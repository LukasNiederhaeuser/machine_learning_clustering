{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.read_data import read_file\n",
    "from src.create_train_test_split import split_predictor_and_target\n",
    "from src.random_forest_model import random_forest_classifier_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and test data\n",
    "df_train = read_file(folder=\"processed\", filename=\"iris_train_processed.csv\", delimiter=\",\")\n",
    "df_test = read_file(folder=\"processed\", filename=\"iris_test_processed.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split processed training set\n",
    "X_train, y_train, columns_X_train, columns_y_train = split_predictor_and_target(df=df_train)\n",
    "# split processed test set\n",
    "X_test, y_test, columns_X_test, columns_y_test = split_predictor_and_target(df=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best rf model using grid search\n",
    "rf_model = random_forest_classifier_model(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set using the obtained model\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "--------------------------------------------------\n",
      "Classification Report Random Forest:\n",
      "{0: 'species_setosa', 1: 'species_versicolor', 2: 'species_virginica'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.90      0.90      0.90        10\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "   micro avg       0.94      0.97      0.95        30\n",
      "   macro avg       0.94      0.97      0.95        30\n",
      "weighted avg       0.94      0.97      0.95        30\n",
      " samples avg       0.95      0.97      0.96        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of rf classifier\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "species_names = list(columns_y_train)\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "print(50*'-')\n",
    "# print the classification report\n",
    "print(\"Classification Report Random Forest:\")\n",
    "print({0: species_names[0], 1: species_names[1], 2: species_names[2]})\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** The precision of a class is the ratio of true positives to the sum of true positives and false positives. It measures the accuracy of positive predictions. In other words: Given we predict for example setosa, how accurate is the classifier.\n",
    "\n",
    "**Recall:** The recall of a class is the ratio of true positives to the sum of true positives and false negatives. It measures the ability of the classifier to find all positive instances. Or in other words, did we get all the observations of a specific iris class?\n",
    "\n",
    "**F1-score:** The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall.\n",
    "\n",
    "**Support:** The support is the number of actual occurrences of the class in the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
