{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.read_data import read_file\n",
    "from src.create_train_test_split import split_predictor_and_target\n",
    "from src.xgboost_model import xgboost_classifier_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and test data\n",
    "df_train = read_file(folder=\"processed\", filename=\"iris_train_processed.csv\", delimiter=\",\")\n",
    "df_test = read_file(folder=\"processed\", filename=\"iris_test_processed.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split processed training set\n",
    "X_train, y_train, columns_X_train, columns_y_train = split_predictor_and_target(df=df_train)\n",
    "# split processed test set\n",
    "X_test, y_test, columns_X_test, columns_y_test = split_predictor_and_target(df=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best xg boost model using grid search\n",
    "xgb_model = xgboost_classifier_model(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set using the obtained model\n",
    "y_pred_xgb = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9333333333333333\n",
      "--------------------------------------------------\n",
      "Classification Report XGBoost:\n",
      "{0: 'species_setosa', 1: 'species_versicolor', 2: 'species_virginica'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.90      0.90      0.90        10\n",
      "\n",
      "   micro avg       0.97      0.93      0.95        30\n",
      "   macro avg       0.97      0.93      0.95        30\n",
      "weighted avg       0.97      0.93      0.95        30\n",
      " samples avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lukas\\projects\\machine_learning_clustering\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of xgb classifier\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "species_names = list(columns_y_train)\n",
    "print(\"Accuracy:\", accuracy_xgb)\n",
    "print(50*'-')\n",
    "# print the classification report\n",
    "print(\"Classification Report XGBoost:\")\n",
    "print({0: species_names[0], 1: species_names[1], 2: species_names[2]})\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Precision:** The precision of a class is the ratio of true positives to the sum of true positives and false positives. It measures the accuracy of positive predictions. In other words: Given we predict for example setosa, how accurate is the classifier.\n",
    "\n",
    "**Recall:** The recall of a class is the ratio of true positives to the sum of true positives and false negatives. It measures the ability of the classifier to find all positive instances. Or in other words, did we get all the observations of a specific iris class?\n",
    "\n",
    "**F1-score:** The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall.\n",
    "\n",
    "**Support:** The support is the number of actual occurrences of the class in the test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
